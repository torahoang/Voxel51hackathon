{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Dataset\n"],"metadata":{"id":"Et--AiJ3NQ30"}},{"cell_type":"code","source":[],"metadata":{"id":"fkCIK1VONT8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iapb3SCkNT4k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Is-n4AYQNT2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7e2sxhwVNTzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lVMp-OvENTwZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"oPMSziGzL5KJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","\n","class TemporalConvBlock(nn.Module):\n","    \"\"\"A residual block with two 1D convolutions, BatchNorm, ReLU, and residual connection.\"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, dilation, stride=1, dropout=0.2):\n","        super(TemporalConvBlock, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n","                               stride=stride, padding=(kernel_size - 1) // 2, dilation=dilation)\n","        self.bn1 = nn.BatchNorm1d(out_channels)  # Batch Normalization after the first convolution\n","\n","        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n","                               stride=stride, padding=(kernel_size - 1) // 2, dilation=dilation)\n","        self.bn2 = nn.BatchNorm1d(out_channels)  # Batch Normalization after the second convolution\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","\n","        # Define a 1x1 Conv for adjusting input dimensions (if in_channels != out_channels)\n","        self.residual_connection = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n","\n","    def forward(self, x):\n","        residual = self.residual_connection(x)\n","        out = self.conv1(x)\n","        out = self.bn1(out)  # Apply BatchNorm after first convolution\n","        out = self.relu(out)\n","        out = self.dropout(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)  # Apply BatchNorm after second convolution\n","        out = out + residual  # Residual connection\n","        out = self.relu(out)\n","        return out\n","\n","class TemporalResNet(nn.Module):\n","    \"\"\"ResNet model with temporal convolutional layers.\"\"\"\n","    def __init__(self, input_channels, num_classes, num_blocks, hidden_channels=64, kernel_size=3, dilation=1, dropout=0.2):\n","        super(TemporalResNet, self).__init__()\n","        self.input_layer = nn.Conv1d(input_channels, hidden_channels, kernel_size=1)\n","\n","        # Stack the specified number of residual blocks\n","        layers = []\n","        for _ in range(num_blocks):\n","            layers.append(TemporalConvBlock(hidden_channels, hidden_channels, kernel_size, dilation, dropout=dropout))\n","        self.residual_layers = nn.Sequential(*layers)\n","\n","        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n","        self.output_layer = nn.Linear(hidden_channels, num_classes)\n","\n","    def forward(self, x):\n","        x = self.input_layer(x)\n","        x = self.residual_layers(x)\n","        x = self.global_avg_pool(x).squeeze(-1)  # Global average pooling across time dimension\n","        x = self.output_layer(x)\n","        return x\n","\n","\n","class TemporalResNetMultiInput(nn.Module):\n","    def __init__(self, imu_channels, video_channels, num_classes, num_blocks, hidden_channels=64, kernel_size=3, dilation=1, dropout=0.2):\n","        super(TemporalResNetMultiInput, self).__init__()\n","\n","        # Separate input layers for IMU and video\n","        self.imu_input_layer = nn.Conv1d(imu_channels, hidden_channels, kernel_size=1)\n","        self.video_input_layer = nn.Conv1d(video_channels, hidden_channels, kernel_size=1)\n","\n","        # Separate residual layers for IMU and video\n","        imu_layers = [TemporalConvBlock(hidden_channels, hidden_channels, kernel_size, dilation, dropout=dropout) for _ in range(num_blocks)]\n","        video_layers = [TemporalConvBlock(hidden_channels, hidden_channels, kernel_size, dilation, dropout=dropout) for _ in range(num_blocks)]\n","        self.imu_residual_layers = nn.Sequential(*imu_layers)\n","        self.video_residual_layers = nn.Sequential(*video_layers)\n","\n","        # Global pooling to ensure compatibility for different input sequence lengths\n","        self.imu_global_pool = nn.AdaptiveAvgPool1d(1)\n","        self.video_global_pool = nn.AdaptiveAvgPool1d(1)\n","\n","        # Output layer after fusion\n","        self.output_layer = nn.Linear(hidden_channels * 2, num_classes)\n","\n","    def forward(self, imu_data, video_data):\n","        # Process IMU data\n","        imu_data = self.imu_input_layer(imu_data)\n","        imu_data = self.imu_residual_layers(imu_data)\n","        imu_data = self.imu_global_pool(imu_data).squeeze(-1)  # Global avg pooling to get (batch_size, hidden_channels)\n","\n","        # Process video data\n","        video_data = self.video_input_layer(video_data)\n","        video_data = self.video_residual_layers(video_data)\n","        video_data = self.video_global_pool(video_data).squeeze(-1)  # Global avg pooling to get (batch_size, hidden_channels)\n","\n","        # Concatenate pooled outputs\n","        combined = torch.cat([imu_data, video_data], dim=1)  # Shape: (batch_size, hidden_channels * 2)\n","        output = self.output_layer(combined)\n","        return output\n","\n","\n","# Single Input TemporalResNet\n","\n","def TemporalResNet14(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=14, **kwargs)\n","\n","def TemporalResNet20(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=20, **kwargs)\n","\n","def TemporalResNet26(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=26, **kwargs)\n","\n","def TemporalResNet32(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=32, **kwargs)\n","\n","def TemporalResNet56(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=56, **kwargs)\n","\n","def TemporalResNet110(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=110, **kwargs)\n","\n","def TemporalResNet164(input_channels, num_classes, **kwargs):\n","    return TemporalResNet(input_channels, num_classes, num_blocks=164, **kwargs)\n","\n","\n","# Multi-Input TemporalResNet\n","\n","def TemporalResNet14MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=14, **kwargs)\n","\n","def TemporalResNet20MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=20, **kwargs)\n","\n","def TemporalResNet26MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=26, **kwargs)\n","\n","def TemporalResNet32MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=32, **kwargs)\n","\n","def TemporalResNet56MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=56, **kwargs)\n","\n","def TemporalResNet110MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=110, **kwargs)\n","\n","def TemporalResNet164MultiInput(imu_channels, video_channels, num_classes, **kwargs):\n","    return TemporalResNetMultiInput(imu_channels, video_channels, num_classes, num_blocks=164, **kwargs)"],"metadata":{"id":"sWCicGCdM7n-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import argparse\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","sys.path.append(os.path.dirname(os.getcwd()))\n","import utils.modeling as models\n","from utils.loadutils import *\n","\n","import multiprocessing\n","multiprocessing.set_start_method('spawn', force=True)\n","\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--seed\", type=int, required=True)\n","parser.add_argument(\"--dpath\", type=str, required=True)\n","parser.add_argument(\"--model_out_path\", type=str, required=True)\n","parser.add_argument(\"--activities\", type=str, required=True)\n","parser.add_argument(\"--secs\", type=float, required=True)\n","parser.add_argument(\"--split\", type=float, required=True)\n","parser.add_argument(\"--batch_size\", type=int, required=True)\n","parser.add_argument(\"--depth\", type=int, required=True)\n","parser.add_argument(\"--epochs\", type=int, required=True)\n","parser.add_argument(\"--lr\", type=float, required=True)\n","parser.add_argument(\"--factor\", type=float, required=True)\n","parser.add_argument(\"--patience\", type=int, required=True)\n","parser.add_argument(\"--cv_folds\", type=int, required=True)\n","parser.add_argument(\"--early_stop_patience\", type=int, required=True)\n","parser.add_argument(\"--modelname\", type=str, required=True)\n","args = parser.parse_args()\n","\n","# Parse JSON-formatted activities list\n","activities = json.loads(args.activities)\n","num_classes = len(activities)\n","\n","# Load data\n","secs = args.secs\n","imu_window_size = int(secs * 50)\n","video_window_size = int(secs * 30)\n","print('IMU Data window size:', imu_window_size)\n","print('Video Data window size:', video_window_size)\n","\n","# Define main function\n","def main():\n","    activities = json.loads(args.activities)\n","    num_classes = len(activities)\n","    set_random_seed(args.seed)\n","\n","    # Initialize KFold here\n","    kf = KFold(n_splits=args.cv_folds, shuffle=True, random_state=args.seed)\n","\n","    ins='VID'\n","    out='act'\n","    dataset = VIDIMU(args.dpath,\n","                     args.secs,\n","                     activities=activities,\n","                     ins=ins,\n","                     out=out)\n","\n","    for fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n","        train_loader, test_loader = loaders_cv(dataset,\n","                                               fold,\n","                                               train_idx,\n","                                               test_idx,\n","                                               ins, out,\n","                                               args.batch_size,\n","                                               args.cv_folds,\n","                                               args.seed)\n","\n","        for in_batch, _ in train_loader:\n","            input_channels = in_batch.shape[1]\n","            break\n","\n","        model = models.TemporalResNet(input_channels, num_classes, num_blocks=args.depth)\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience)\n","\n","        train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, args.modelname, args.seed, fold, num_epochs=args.epochs)\n","        print(f\"Completed fold {fold + 1}/{args.cv_folds}\\n\")\n","\n","def test_model(model, test_loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for X_batch, y_batch in test_loader:\n","            X_batch = X_batch.float()\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(y_batch.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=1)\n","    return accuracy, precision, recall, f1\n","\n","def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, modelname, seed, fold, num_epochs=20):\n","    model.train()\n","    best_accuracy = 0.0\n","    best_model_filename = None\n","    no_improvement_epochs = 0\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for X_batch, y_batch in train_loader:\n","            X_batch, y_batch = X_batch.float(), y_batch.long()\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            correct_train += (predicted == y_batch).sum().item()\n","            total_train += y_batch.size(0)\n","\n","        train_accuracy = correct_train / total_train\n","\n","        test_accuracy, precision, recall, f1 = test_model(model, test_loader)\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n","              f\"Loss: {total_loss / len(train_loader):.4f}, \"\n","              f\"Train Accuracy: {train_accuracy:.4f}, \"\n","              f\"Test Accuracy: {test_accuracy:.4f}, \"\n","              f\"Precision: {precision:.4f}, \"\n","              f\"Recall: {recall:.4f}, \"\n","              f\"F1-Score: {f1:.4f}\")\n","\n","        scheduler.step(test_accuracy)\n","        current_lr = optimizer.param_groups[0]['lr']\n","        print(f\"Current learning rate: {current_lr:.1e}\")\n","\n","        if test_accuracy > best_accuracy:\n","            if best_model_filename is not None and os.path.exists(best_model_filename):\n","                os.remove(best_model_filename)\n","\n","            best_accuracy = test_accuracy\n","            best_model_filename = f'{args.model_out_path}/best_{modelname}_fold{fold+1}_{args.depth}_{args.secs}_{seed}_acc_{best_accuracy:.4f}.pth'\n","            torch.save(model.state_dict(), best_model_filename)\n","            print(f\"New best model for fold {fold+1} saved as {best_model_filename}\")\n","            no_improvement_epochs = 0\n","        else:\n","            no_improvement_epochs += 1\n","\n","        if no_improvement_epochs >= args.early_stop_patience:\n","            print(f\"Early stopping triggered after {no_improvement_epochs} epochs without improvement.\")\n","            break\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"4ax-nkyJL4ak"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finetuning"],"metadata":{"id":"fxK-lXZ5L8TJ"}},{"cell_type":"code","source":[],"metadata":{"id":"NNzqxts1L4AJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KD"],"metadata":{"id":"JdXWrrbPLi3Z"}},{"cell_type":"code","source":["import glob\n","import os\n","import sys\n","import argparse\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","import multiprocessing\n","multiprocessing.set_start_method('spawn', force=True)\n","\n","sys.path.append(os.path.dirname(os.getcwd()))\n","import utils.modeling as models\n","from utils.loadutils import *\n","\n","\n","# parser = argparse.ArgumentParser()\n","# parser.add_argument(\"--seed\", type=int, required=True)\n","# parser.add_argument(\"--dpath\", type=str, required=True)\n","# parser.add_argument(\"--model_out_path\", type=str, required=True)\n","# parser.add_argument(\"--activities\", type=str, required=True)\n","# parser.add_argument(\"--secs\", type=float, required=True)\n","# parser.add_argument(\"--split\", type=float, required=True)\n","# parser.add_argument(\"--batch_size\", type=int, required=True)\n","# parser.add_argument(\"--depth\", type=int, required=True)\n","# parser.add_argument(\"--epochs\", type=int, required=True)\n","# parser.add_argument(\"--lr\", type=float, required=True)\n","# parser.add_argument(\"--factor\", type=float, required=True)\n","# parser.add_argument(\"--patience\", type=int, required=True)\n","# parser.add_argument(\"--early_stop_patience\", type=int, required=True)\n","# args = parser.parse_args()\n","\n","\n","def distillation_loss(student_logits, teacher_logits, true_labels):\n","    alpha = 0.7\n","    temperature = 5\n","    hard_loss = nn.CrossEntropyLoss()(student_logits, true_labels)\n","\n","    soft_teacher_probs = nn.functional.softmax(teacher_logits / temperature, dim=1)\n","    soft_student_probs = nn.functional.log_softmax(student_logits / temperature, dim=1)\n","    distill_loss = nn.functional.kl_div(soft_student_probs, soft_teacher_probs, reduction='batchmean') * (temperature ** 2)\n","\n","    return alpha * distill_loss + (1 - alpha) * hard_loss\n","\n","def test_model(student_model, test_loader, return_accuracy=False):\n","    student_model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for vid_batch, _, y_batch in test_loader:\n","            vid_batch = vid_batch.float()\n","            outputs = student_model(vid_batch)\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(y_batch.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=1)\n","    return accuracy, precision, recall, f1\n","\n","def train_distillation(student_model, teacher_model, train_loader, test_loader, distillation_loss, optimizer, scheduler, modelname, num_epochs=20, model_path=None):\n","\n","    if model_path and os.path.exists(model_path):\n","        student_model.load_state_dict(torch.load(model_path, weights_only=True))\n","        print(f\"Loaded student model from {model_path}\")\n","\n","    student_model.train()\n","    best_accuracy = 0.0\n","    best_model_filename = None\n","    no_improvement_epochs = 0\n","    train_accuracies = []\n","    test_accuracies = []\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for vid_batch, imu_batch, y_batch in train_loader:\n","            vid_batch = vid_batch.float()\n","            imu_batch = imu_batch.float()\n","            y_batch = y_batch.long()\n","            optimizer.zero_grad()\n","\n","            with torch.no_grad():\n","                teacher_logits = teacher_model(imu_batch, vid_batch)\n","\n","            student_logits = student_model(vid_batch)\n","\n","            loss = distillation_loss(student_logits, teacher_logits, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            _, predicted = torch.max(student_logits, 1)\n","            correct_train += (predicted == y_batch).sum().item()\n","            total_train += y_batch.size(0)\n","\n","        train_accuracy = correct_train / total_train\n","        train_accuracies.append(train_accuracy)\n","\n","        test_accuracy, precision, recall, f1 = test_model(student_model, test_loader)\n","        test_accuracies.append(test_accuracy)\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n","              f\"Loss: {total_loss / len(train_loader):.4f}, \"\n","              f\"Train Accuracy: {train_accuracy:.4f}, \"\n","              f\"Test Accuracy: {test_accuracy:.4f}, \"\n","              f\"Precision: {precision:.4f}, \"\n","              f\"Recall: {recall:.4f}, \"\n","              f\"F1-Score: {f1:.4f}\")\n","\n","        scheduler.step(test_accuracy)\n","        current_lr = optimizer.param_groups[0]['lr']\n","        print(f\"Current learning rate: {current_lr:.1e}\")\n","\n","        if test_accuracy > best_accuracy:\n","            if best_model_filename is not None and os.path.exists(best_model_filename):\n","                os.remove(best_model_filename)\n","\n","            best_accuracy = test_accuracy\n","            best_model_filename = f'{args.model_out_path}/best_{modelname}_{args.depth}_{args.secs}_{args.seed}_acc_{best_accuracy:.4f}.pth'\n","            torch.save(student_model.state_dict(), best_model_filename)\n","            print(f\"New best model saved as {best_model_filename}\")\n","            no_improvement_epochs = 0\n","        else:\n","            no_improvement_epochs += 1\n","\n","        if no_improvement_epochs >= args.early_stop_patience:\n","            print(f\"Early stopping triggered after {no_improvement_epochs} epochs without improvement.\")\n","            break\n","\n","\n","def main():\n","    secs = args.secs\n","    imu_window_size = int(secs * 50)\n","    video_window_size = int(secs * 30)\n","    print('IMU Data window size:', imu_window_size)\n","    print('Video Data window size:', video_window_size)\n","    activities = json.loads(args.activities)\n","    num_classes = len(activities)\n","    fold = 1\n","    set_random_seed(args.seed)\n","\n","    train_loader, test_loader = standardize_vidimu(args.dpath,\n","                                                   time_in_seconds=secs,\n","                                                   split=0.8,\n","                                                   batch_size=32,\n","                                                   activities = activities,\n","                                                   ins='VIDIMU',\n","                                                   out='act')\n","\n","    for vid_batch, imu_batch, _ in train_loader:\n","        vid_channels = vid_batch.shape[1]\n","        imu_channels = imu_batch.shape[1]\n","        break\n","\n","    student_model = models.TemporalResNet(input_channels=vid_channels, num_classes=num_classes, num_blocks=args.depth)\n","    teacher_model = models.TemporalResNetMultiInput(imu_channels, vid_channels, num_classes, num_blocks=args.depth)\n","\n","    teacher_name = f'/Volumes/Data_Drive/vidimu_gridsearch_out/gridsearch_11_4/best_AngPos_ResNet_fold{fold}_{args.depth}_{args.secs}_{args.seed}_acc_'\n","    teacher_path = glob.glob(teacher_name+'*')[0]\n","    # print('TEACHER PATH ------> ', teacher_path)\n","    student_name = f'/Volumes/Data_Drive/vidimu_gridsearch_out/gridsearch_11_4/best_Pos_ResNet_fold{fold}_{args.depth}_{args.secs}_{args.seed}_acc_'\n","    student_path = glob.glob(student_name+'*')[0]\n","    # print('STUDENT PATH ------> ', student_path)\n","\n","    teacher_model.load_state_dict(torch.load(teacher_path, weights_only=True))\n","    teacher_model.eval()\n","\n","    epochs = args.epochs\n","    optimizer = optim.Adam(student_model.parameters(), lr=0.0001)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=args.factor, patience=args.patience)\n","\n","    train_distillation(student_model, teacher_model, train_loader, test_loader, distillation_loss, optimizer, scheduler, modelname='Pos_ResNetKD', num_epochs=epochs, model_path=student_path)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"xeHSY4wdLd6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aL_q5egsLd2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SUYCNWohLd0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mojy5FkILdw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CaPtNt2eLdtx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uesa4EI5LdoV"},"execution_count":null,"outputs":[]}]}